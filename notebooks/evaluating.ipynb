{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "from pylab import savefig\n",
    "from nltk.tag import StanfordNERTagger\n",
    "from nltk.tokenize import word_tokenize\n",
    "import os\n",
    "from nltk.metrics.scores import accuracy\n",
    "from nltk.metrics.scores import recall\n",
    "from nltk.metrics.scores import precision\n",
    "from nltk.metrics.scores import f_measure\n",
    "import zipfile\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "java_path = \"C:/Program Files/Java/jdk1.8.0_101/bin/java.exe\"\n",
    "os.environ['JAVAHOME'] = java_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_values(pc, fmt=\"%.2f\", **kw):\n",
    "    '''\n",
    "    Heatmap with text in each cell with matplotlib's pyplot\n",
    "    Source: http://stackoverflow.com/a/25074150/395857 \n",
    "    By HYRY\n",
    "    '''\n",
    "    from itertools import izip\n",
    "    pc.update_scalarmappable()\n",
    "    ax = pc.get_axes()\n",
    "    for p, color, value in izip(pc.get_paths(), pc.get_facecolors(), pc.get_array()):\n",
    "        x, y = p.vertices[:-2, :].mean(0)\n",
    "        if np.all(color[:3] > 0.5):\n",
    "            color = (0.0, 0.0, 0.0)\n",
    "        else:\n",
    "            color = (1.0, 1.0, 1.0)\n",
    "        ax.text(x, y, fmt % value, ha=\"center\", va=\"center\", color=color, **kw)\n",
    "\n",
    "\n",
    "def cm2inch(*tupl):\n",
    "    '''\n",
    "    Specify figure size in centimeter in matplotlib\n",
    "    Source: http://stackoverflow.com/a/22787457/395857\n",
    "    By gns-ank\n",
    "    '''\n",
    "    inch = 2.54\n",
    "    if type(tupl[0]) == tuple:\n",
    "        return tuple(i/inch for i in tupl[0])\n",
    "    else:\n",
    "        return tuple(i/inch for i in tupl)\n",
    "\n",
    "\n",
    "def heatmap(AUC, title, xlabel, ylabel, xticklabels, yticklabels, figure_width=40, figure_height=20, correct_orientation=False, cmap='RdBu'):\n",
    "    '''\n",
    "    Inspired by:\n",
    "    - http://stackoverflow.com/a/16124677/395857 \n",
    "    - http://stackoverflow.com/a/25074150/395857\n",
    "    '''\n",
    "\n",
    "    # Plot it out\n",
    "    fig, ax = plt.subplots()    \n",
    "    #c = ax.pcolor(AUC, edgecolors='k', linestyle= 'dashed', linewidths=0.2, cmap='RdBu', vmin=0.0, vmax=1.0)\n",
    "    c = ax.pcolor(AUC, edgecolors='k', linestyle= 'dashed', linewidths=0.2, cmap=cmap)\n",
    "\n",
    "    # put the major ticks at the middle of each cell\n",
    "    ax.set_yticks(np.arange(AUC.shape[0]) + 0.5, minor=False)\n",
    "    ax.set_xticks(np.arange(AUC.shape[1]) + 0.5, minor=False)\n",
    "\n",
    "    # set tick labels\n",
    "    #ax.set_xticklabels(np.arange(1,AUC.shape[1]+1), minor=False)\n",
    "    ax.set_xticklabels(xticklabels, minor=False)\n",
    "    ax.set_yticklabels(yticklabels, minor=False)\n",
    "\n",
    "    # set title and x/y labels\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)      \n",
    "\n",
    "    # Remove last blank column\n",
    "    plt.xlim( (0, AUC.shape[1]) )\n",
    "\n",
    "    # Turn off all the ticks\n",
    "    ax = plt.gca()    \n",
    "    for t in ax.xaxis.get_major_ticks():\n",
    "        t.tick1On = False\n",
    "        t.tick2On = False\n",
    "    for t in ax.yaxis.get_major_ticks():\n",
    "        t.tick1On = False\n",
    "        t.tick2On = False\n",
    "\n",
    "    # Add color bar\n",
    "    plt.colorbar(c)\n",
    "\n",
    "    # Add text in each cell \n",
    "    show_values(c)\n",
    "\n",
    "    # Proper orientation (origin at the top left instead of bottom left)\n",
    "    if correct_orientation:\n",
    "        ax.invert_yaxis()\n",
    "        ax.xaxis.tick_top()       \n",
    "\n",
    "    # resize \n",
    "    fig = plt.gcf()\n",
    "    #fig.set_size_inches(cm2inch(40, 20))\n",
    "    #fig.set_size_inches(cm2inch(40*4, 20*4))\n",
    "    fig.set_size_inches(cm2inch(figure_width, figure_height))\n",
    "\n",
    "\n",
    "\n",
    "def plot_classification_report(classification_report, title='Classification report ', cmap='RdBu'):\n",
    "    '''\n",
    "    Plot scikit-learn classification report.\n",
    "    Extension based on http://stackoverflow.com/a/31689645/395857 \n",
    "    '''\n",
    "    lines = classification_report.split('\\n')\n",
    "\n",
    "    classes = []\n",
    "    plotMat = []\n",
    "    support = []\n",
    "    class_names = []\n",
    "    for line in lines[2 : (len(lines) - 2)]:\n",
    "        t = line.strip().split()\n",
    "        if len(t) < 2: continue\n",
    "        classes.append(t[0])\n",
    "        v = [float(x) for x in t[1: len(t) - 1]]\n",
    "        support.append(int(t[-1]))\n",
    "        class_names.append(t[0])\n",
    "        print(v)\n",
    "        plotMat.append(v)\n",
    "\n",
    "    print('plotMat: {0}'.format(plotMat))\n",
    "    print('support: {0}'.format(support))\n",
    "\n",
    "    xlabel = 'Metrics'\n",
    "    ylabel = 'Classes'\n",
    "    xticklabels = ['Precision', 'Recall', 'F1-score']\n",
    "    yticklabels = ['{0} ({1})'.format(class_names[idx], sup) for idx, sup  in enumerate(support)]\n",
    "    figure_width = 25\n",
    "    figure_height = len(class_names) + 7\n",
    "    correct_orientation = False\n",
    "    heatmap(np.array(plotMat), title, xlabel, ylabel, xticklabels, yticklabels, figure_width, figure_height, correct_orientation, cmap=cmap)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_model(path):\n",
    "    model = StanfordNERTagger(path,\n",
    "                       '../libs/stanford-ner.jar',\n",
    "                       encoding='utf-8')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def to4classes(items):\n",
    "    d4 = []\n",
    "    for item in items:\n",
    "        if item == 'O' or item == 'B-NOT':\n",
    "            d4.append('O')\n",
    "        else:\n",
    "            d4.append(item.split(\"-\")[1])\n",
    "    return d4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def choose_words(lines):\n",
    "    lst = []\n",
    "    for line in lines:\n",
    "        lst.append(line.split(\" \")[0])\n",
    "    return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reference_classes(lines):\n",
    "    arr = []\n",
    "    for line in lines:\n",
    "        s2 = line.split(\" \")[2]\n",
    "        s2 = s2.split(\"\\n\")[0]\n",
    "        u2 = unicode(s2, \"utf-8\")\n",
    "        arr.append(u2)\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(model, data):\n",
    "    model_pred = model.tag(data)\n",
    "    model_ypred = [x[1] for x in model_pred]\n",
    "    model_ypred4 = to4classes(model_ypred)\n",
    "    return model_ypred4  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(y_true, y_pred, target_names, filename):\n",
    "    plot_classification_report(classification_report(y_true, y_pred, target_names))\n",
    "    plt.savefig(filename, dpi=200, format='png', bbox_inches='tight')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n\n===========================================================================\nNLTK was unable to find the ../models/model1.ser.gz file!\nUse software specific configuration paramaters or set the STANFORD_MODELS environment variable.\n===========================================================================",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-d282a0e83493>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#load models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmy_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../models/model1.ser.gz\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mout_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../models/eunews.nl.crf.gz\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-33-3c25a3ef678d>\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m      2\u001b[0m     model = StanfordNERTagger(path,\n\u001b[1;32m      3\u001b[0m                        \u001b[0;34m'../libs/stanford-ner.jar'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m                        encoding='utf-8')\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nfs/home/gkonoplich/workspace/env2/local/lib/python2.7/site-packages/nltk/tag/stanford.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mStanfordNERTagger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nfs/home/gkonoplich/workspace/env2/local/lib/python2.7/site-packages/nltk/tag/stanford.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model_filename, path_to_jar, encoding, verbose, java_options)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         self._stanford_model = find_file(model_filename,\n\u001b[0;32m---> 56\u001b[0;31m                 env_vars=('STANFORD_MODELS',), verbose=verbose)\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;31m# Adding logging jar files to classpath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nfs/home/gkonoplich/workspace/env2/local/lib/python2.7/site-packages/nltk/__init__.pyc\u001b[0m in \u001b[0;36mfind_file\u001b[0;34m(filename, env_vars, searchpath, file_names, url, verbose)\u001b[0m\n\u001b[1;32m    571\u001b[0m         file_names=None, url=None, verbose=True):\n\u001b[1;32m    572\u001b[0m     return next(find_file_iter(filename, env_vars, searchpath,\n\u001b[0;32m--> 573\u001b[0;31m                                file_names, url, verbose))\n\u001b[0m\u001b[1;32m    574\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/nfs/home/gkonoplich/workspace/env2/local/lib/python2.7/site-packages/nltk/__init__.pyc\u001b[0m in \u001b[0;36mfind_file_iter\u001b[0;34m(filename, env_vars, searchpath, file_names, url, verbose, finding_dir)\u001b[0m\n\u001b[1;32m    565\u001b[0m                         (filename, url))\n\u001b[1;32m    566\u001b[0m         \u001b[0mdiv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'='\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m75\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 567\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n\\n%s\\n%s\\n%s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdiv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    568\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLookupError\u001b[0m: \n\n===========================================================================\nNLTK was unable to find the ../models/model1.ser.gz file!\nUse software specific configuration paramaters or set the STANFORD_MODELS environment variable.\n==========================================================================="
     ]
    }
   ],
   "source": [
    "#load models\n",
    "my_model = load_model(\"../models/model1.ser.gz\")\n",
    "out_model = load_model(\"../models/eunews.nl.crf.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#ftest_data = open(\"../datasets/processed/data_test1.bio\", \"r\")\n",
    "ftest_data = open(\"C:/workspace/nlp/ner/ner_historicpapers/datasets/data_test1.bio\", \"r\")\n",
    "fall_data = open(\"../datasets/processed/combined_data.bio\", \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data = ftest_data.readlines()\n",
    "all_data = fall_data.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#getting words and reference classes for different data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_words = choose_words(test_data)\n",
    "all_words = choose_words(all_data)\n",
    "y_test = reference_classes(test_data)\n",
    "y_all_data = reference_classes(all_data)\n",
    "y_test4 = to4classes(y_test)\n",
    "y_all_data4 = to4classes(y_all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_model_ypred4 = predict(my_model, test_words)\n",
    "out_model_ypred4 = predict(out_model, test_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classes = list(set(y_test4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.53, 0.63, 0.57]\n",
      "[0.47, 0.41, 0.44]\n",
      "[0.98, 0.98, 0.98]\n",
      "[0.52, 0.43, 0.47]\n",
      "plotMat: [[0.53, 0.63, 0.57], [0.47, 0.41, 0.44], [0.98, 0.98, 0.98], [0.52, 0.43, 0.47]]\n",
      "support: [824, 1028, 43599, 170]\n"
     ]
    }
   ],
   "source": [
    "evaluate(y_test4, my_model_ypred4, classes, \"my_model_test0.25.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.28, 0.99, 0.44]\n",
      "[0.31, 1.0, 0.47]\n",
      "[1.0, 0.86, 0.92]\n",
      "[0.08, 0.99, 0.15]\n",
      "plotMat: [[0.28, 0.99, 0.44], [0.31, 1.0, 0.47], [1.0, 0.86, 0.92], [0.08, 0.99, 0.15]]\n",
      "support: [824, 1028, 43599, 170]\n"
     ]
    }
   ],
   "source": [
    "evaluate(y_test4, out_model_ypred4, classes, \"out_model_test0.25.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_model_ypred4 = predict(my_model, all_words)\n",
    "out_model_ypred4 = predict(out_model, all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9, 0.93, 0.91]\n",
      "[0.89, 0.86, 0.87]\n",
      "[0.99, 0.99, 0.99]\n",
      "[0.94, 0.91, 0.93]\n",
      "plotMat: [[0.9, 0.93, 0.91], [0.89, 0.86, 0.87], [0.99, 0.99, 0.99], [0.94, 0.91, 0.93]]\n",
      "support: [4448, 4473, 172403, 1158]\n"
     ]
    }
   ],
   "source": [
    "evaluate(y_all_data4, my_model_ypred4, classes, \"my_model_all_data.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.41, 0.99, 0.58]\n",
      "[0.4, 1.0, 0.57]\n",
      "[1.0, 0.88, 0.94]\n",
      "[0.13, 0.99, 0.24]\n",
      "plotMat: [[0.41, 0.99, 0.58], [0.4, 1.0, 0.57], [1.0, 0.88, 0.94], [0.13, 0.99, 0.24]]\n",
      "support: [4448, 4473, 172403, 1158]\n"
     ]
    }
   ],
   "source": [
    "evaluate(y_all_data4, out_model_ypred4, classes, \"out_model_all_data.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        LOC       0.41      0.99      0.58      4448\n",
      "        PER       0.40      1.00      0.57      4473\n",
      "          O       1.00      0.88      0.94    172403\n",
      "        ORG       0.13      0.99      0.24      1158\n",
      "\n",
      "avg / total       0.97      0.89      0.92    182482\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_all_data4, out_model_ypred4, classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#new experiments with new 4-fold evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model2 = load_model(\"../models/model4.crf.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ftest_data = open(\"../datasets/processed/data_test4.bio\", \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data = ftest_data.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_words = choose_words(test_data)\n",
    "y_test = reference_classes(test_data)\n",
    "y_test4 = to4classes(y_test)\n",
    "classes = list(set(y_test4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model2_ypred4 = predict(model2, test_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45620"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.86, 0.59, 0.7]\n",
      "[0.91, 0.42, 0.57]\n",
      "[0.96, 1.0, 0.98]\n",
      "[0.86, 0.24, 0.38]\n",
      "plotMat: [[0.86, 0.59, 0.7], [0.91, 0.42, 0.57], [0.96, 1.0, 0.98], [0.86, 0.24, 0.38]]\n",
      "support: [1084, 1601, 42590, 345]\n"
     ]
    }
   ],
   "source": [
    "evaluate(y_test4, model2_ypred4, classes, \"model3_test2_data.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
